{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOSKewDLCEWJKQG4ylBzzJH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# はじめに\n","LLMを実行するためのサンプルコードです。\n","\n","### 概要\n","- Llamaの小型モデルを動かします。\n","- 認証などについても説明します。\n","\n","# 事前準備\n","1. Hugging Faceのアカウント作成\n","2. アクセストークンの作成  \n","Hugging Faceのアカウントにログインし、「自分のアイコン→Settings→Access Tokens→+ Create new token」からトークンを作成します。  \n","「Read access to contents of all public gated repos you can access」の権限が必要となります。  \n","3. Llamaの利用申請  \n","Hugging Faceで使用したいモデルのページにアクセスして、必要事項を記入して申請します。  \n","申請が承認されると利用可能になります。\n"],"metadata":{"id":"Ovr_4hfgSZDc"}},{"cell_type":"markdown","source":["# 実装\n","### 1. ライブラリのインポート"],"metadata":{"id":"wBQdksXZKUZc"}},{"cell_type":"code","source":["import sys\n","import os\n","\n","!pip install -U bitsandbytes\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","import torch"],"metadata":{"id":"yZ3XOhWWTCmU","executionInfo":{"status":"ok","timestamp":1729407343833,"user_tz":-540,"elapsed":13693,"user":{"displayName":"toshi-4886","userId":"12494440849966135661"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f59c4f1-d8f1-4134-ddef-ec59c36504ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bitsandbytes\n","  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.44.1\n"]}]},{"cell_type":"markdown","source":["GPU環境を確認します。  "],"metadata":{"id":"WkvqGnuzTUvv"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZkCapMgWTWVo","executionInfo":{"status":"ok","timestamp":1729408143535,"user_tz":-540,"elapsed":493,"user":{"displayName":"toshi-4886","userId":"12494440849966135661"}},"outputId":"ff6c1993-4fd1-4329-99a0-895ccc34ac81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Oct 20 07:09:02 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   77C    P0              31W /  70W |   8349MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["### 2. 認証\n","Hugging Faceからモデルをダウンロードするために、アカウント認証を行います。  \n","login()を実行するとトークンを入力するUIが出てくるので、そこにトークンを入力します。  \n","また、colabのシークレットにトークンを保存しておけば、それを利用することもできます。"],"metadata":{"id":"67paIs1yTZbQ"}},{"cell_type":"code","source":["from huggingface_hub import login\n","# login()\n","\n","# シークレットにトークンを保存しておけば下記で認証可能\n","from google.colab import userdata\n","login(token=userdata.get('HF_TOKEN'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6gMd0VojibE","executionInfo":{"status":"ok","timestamp":1729407384954,"user_tz":-540,"elapsed":10042,"user":{"displayName":"toshi-4886","userId":"12494440849966135661"}},"outputId":"4ee653a7-0316-4d3c-a799-427ff6471ecc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: fineGrained).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}]},{"cell_type":"markdown","source":["### 3. モデルの準備\n","トークナイザーとモデルを準備します。  \n","モデルはv0.3を4bit量子化したものを使用します。"],"metadata":{"id":"nWlG5dyvdJ0T"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\n","    \"meta-llama/Llama-3.2-1B-Instruct\",\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"meta-llama/Llama-3.2-1B-Instruct\",\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\",\n","    trust_remote_code=False,\n",")"],"metadata":{"id":"53UUhXZvUVpR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4. 推論\n","プロンプトをモデルに入力して、得られた出力を表示します。"],"metadata":{"id":"GpzHxeMRjo4f"}},{"cell_type":"code","source":["# 推論時間を計測\n","%%time\n","\n","# プロンプトの準備\n","conversation = [{\"role\": \"user\", \"content\": \"What's the weather like in Paris?\"}]\n","\n","# 推論の実行\n","with torch.no_grad():\n","    token_ids = tokenizer.apply_chat_template(conversation, add_generation_prompt=True,\n","            return_dict=True, return_tensors=\"pt\").to(model.device)\n","    output_ids = model.generate(\n","        **token_ids,\n","        pad_token_id=tokenizer.eos_token_id,\n","        temperature=0.1,\n","        do_sample=True,\n","        top_p=0.95,\n","        top_k=40,\n","        max_new_tokens=256,\n","    )\n","output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","print(output)"],"metadata":{"id":"N4pFUapajs4L","executionInfo":{"status":"ok","timestamp":1729408054648,"user_tz":-540,"elapsed":5850,"user":{"displayName":"toshi-4886","userId":"12494440849966135661"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f8bd1c0f-4c2f-4bee-bf66-d543e4d0422c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["system\n","\n","Cutting Knowledge Date: December 2023\n","Today Date: 26 Jul 2024\n","\n","user\n","\n","What's the weather like in Paris?assistant\n","\n","In Paris, the weather is typically mild and temperate, with four distinct seasons. Here's a breakdown of what you can expect:\n","\n","- Spring (March to May): Spring in Paris is lovely, with mild temperatures ranging from 10°C (50°F) to 20°C (68°F). The days are getting longer, and the sun shines brightly, making it ideal for exploring the city's parks and gardens. However, it can still be quite chilly, especially in the mornings and evenings.\n","- Summer (June to August): Summer in Paris is warm and sunny, with average highs around 25°C (77°F) and lows around 15°C (59°F). It's a great time to visit the city's famous beaches, such as the Champs-Élysées and the Seine River. However, the heat can be intense, especially in July and August.\n","- Autumn (September to November): Autumn in Paris is lovely, with mild temperatures ranging from 10°C (50°F) to 20°C (68°F). The days are getting shorter, and the sun shines brightly, making it ideal for exploring the city's historic sites and museums. However, it can still be quite chilly, especially in the mornings and evenings.\n","- Winter (December\n","CPU times: user 5.32 s, sys: 163 µs, total: 5.32 s\n","Wall time: 5.34 s\n"]}]},{"cell_type":"markdown","source":["# おわりに\n","### 今回の結果\n","Llamaでプロンプトの回答を生成することができました。  \n","一般的な天気を答えているので、ハルシネーションを防ぐための調整もされていることが確認できました。\n","\n","### 次にやること  \n","プロンプトの設定方法について様々な方法を試してみたいと思います。\n","\n","### 参考資料  \n","- meta-llama/Llama-3.2-1B-Instruct  \n","https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct\n"],"metadata":{"id":"V4ijotsLmJsT"}}]}